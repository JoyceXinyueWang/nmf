\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrtnat}
\babel@aux{UKenglish}{}
\citation{lee1999learning}
\citation{guillamet2002non}
\citation{lee1999learning}
\newlabel{chapter1}{{1}{2}{Introduction\label {chapter1}}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{lpc}{\contentsline {lpcsec}{\numberline {}Chen\ - sorry but I do not understand}{2}{section*.1}}
\@writefile{lpc}{\contentsline {lpcsec}{\numberline {}Chen\ - $K$ means is not only a image processing technique, delete}{2}{section*.2}}
\citation{lee2001algorithms}
\citation{lee2001algorithms}
\citation{guan2017truncated}
\citation{yang2011kullback}
\citation{lam2008non}
\citation{kong2011robust}
\citation{guan2017truncated}
\citation{lee2001algorithms}
\citation{lin2007convergence}
\citation{guan2012nenmf}
\citation{berry2007algorithms}
\citation{guan2012nenmf}
\citation{kim2008nonnegative}
\citation{kim2008nonnegative}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{3}{section.2}}
\citation{barbu2013variational}
\citation{lee2001algorithms}
\citation{lee2001algorithms}
\newlabel{chapter2}{{3}{4}{Methods \label {chapter2}}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods }{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}NMF and Gaussian noise}{4}{subsection.3.1}}
\newlabel{eq:obnmf}{{1}{4}{NMF and Gaussian noise}{equation.3.1}{}}
\newlabel{noises}{{3}{5}{Methods \label {chapter2}}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The original images (left) are corrupted by Gaussian Noise (top), Poisson Noise (middle), and Salt \& Pepper Noise (bottom). The corrupted images are shown on the right.}}{5}{figure.1}}
\newlabel{fig:noise}{{1}{5}{The original images (left) are corrupted by Gaussian Noise (top), Poisson Noise (middle), and Salt \& Pepper Noise (bottom). The corrupted images are shown on the right}{figure.1}{}}
\citation{liu2015performance}
\citation{lee2001algorithms}
\citation{lee2001algorithms}
\newlabel{eq:nmf}{{2}{6}{NMF and Gaussian noise}{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}KLNMF and Poisson noise}{6}{subsection.3.2}}
\newlabel{eq:klobj}{{3}{6}{KLNMF and Poisson noise}{equation.3.3}{}}
\newlabel{eq:klnmf}{{4}{6}{KLNMF and Poisson noise}{equation.3.4}{}}
\citation{Walck:1996cca}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Gaussian and Poisson are asymptotic equivalent}{7}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Compare a Gaussian noise~$N(0,40)$ with Poisson noise $\operatorname  {Poi}(40)-40$. They two distributions are asymptotically equivalent and have similar density functions.}}{8}{figure.2}}
\newlabel{noise}{{2}{8}{Compare a Gaussian noise~$N(0,40)$ with Poisson noise $\operatorname {Poi}(40)-40$. They two distributions are asymptotically equivalent and have similar density functions}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Multiple initial estimates avoid local minima}{8}{subsection.3.4}}
\citation{sampat2005computer}
\newlabel{matn1}{{1}{9}{Centring image data}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Centring image data}{9}{lstlisting.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}KLNMF requires more iterations}{9}{subsection.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Salt \& Pepper noise}{9}{subsection.3.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Residual of objective function~\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:obnmf}\unskip \@@italiccorr )}} and~\textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:klobj}\unskip \@@italiccorr )}} versus the number of iterations. \textsc  {nmf} converges more than twice faster than \textsc  {klnmf}.}}{10}{figure.3}}
\newlabel{error}{{3}{10}{Residual of objective function~\eqref {eq:obnmf} and~\eqref {eq:klobj} versus the number of iterations. \textsc {nmf} converges more than twice faster than \textsc {klnmf}}{figure.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{10}{section.4}}
\newlabel{chapter4}{{4}{10}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Noise}{10}{subsection.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{11}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix}{11}{appendix.A}}
\newlabel{matn1}{{2}{11}{The Levenberg--Marquardt algorithm iteratively finds optimal macroscale Robin boundary conditions}{lstlisting.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}The Levenberg--Marquardt algorithm iteratively finds optimal macroscale Robin boundary conditions.}{11}{lstlisting.2}}
\bibdata{research}
\bibcite{lee1999learning}{{1}{1999}{{Lee and Seung}}{{}}}
\bibcite{guillamet2002non}{{2}{2002}{{Guillamet and Vitri{\`a}}}{{}}}
\bibcite{lee2001algorithms}{{3}{2001}{{Lee and Seung}}{{}}}
\bibcite{guan2017truncated}{{4}{2017}{{Guan et~al.}}{{Guan, Liu, Zhang, Tao, and Davis}}}
\bibcite{yang2011kullback}{{5}{2011}{{Yang et~al.}}{{Yang, Zhang, Yuan, and Oja}}}
\bibcite{lam2008non}{{6}{2008}{{Lam}}{{}}}
\bibcite{kong2011robust}{{7}{2011}{{Kong et~al.}}{{Kong, Ding, and Huang}}}
\bibcite{lin2007convergence}{{8}{2007}{{Lin}}{{}}}
\bibcite{guan2012nenmf}{{9}{2012}{{Guan et~al.}}{{Guan, Tao, Luo, and Yuan}}}
\bibcite{berry2007algorithms}{{10}{2007}{{Berry et~al.}}{{Berry, Browne, Langville, Pauca, and Plemmons}}}
\bibcite{kim2008nonnegative}{{11}{2008}{{Kim and Park}}{{}}}
\bibcite{barbu2013variational}{{12}{2013}{{Barbu}}{{}}}
\bibcite{liu2015performance}{{13}{2016}{{Liu and Tao}}{{}}}
\bibcite{Walck:1996cca}{{14}{1996}{{Walck}}{{}}}
\bibcite{sampat2005computer}{{15}{2005}{{Sampat et~al.}}{{Sampat, Markey, Bovik, et~al.}}}
\ulp@afterend
